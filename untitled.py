# -*- coding: utf-8 -*-
"""Untitled

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19z4pE0UQ8R0UYkxIRvPqptx_vPOh2lwb
"""

from google.colab import drive
drive.mount('/content/gdrive')

root_path = 'gdrive/My Drive/HAPT Data Set.zip (Unzipped Files)/'

mainfileX = '/content/gdrive/MyDrive/HAPT Data Set.zip (Unzipped Files)/Train/X_train.txt'
mainfileY = '/content/gdrive/MyDrive/HAPT Data Set.zip (Unzipped Files)/Train/y_train.txt'

#import all libraries
from sklearn.model_selection import train_test_split
from sklearn import svm
from sklearn import decomposition
import numpy as np
import matplotlib.pyplot as plt
from pdb import set_trace as bp
from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV
import pandas as pd

#load text files to array
X_tr = np.loadtxt(mainfileX,delimiter=' ')
Y_tr = np.loadtxt(mainfileY)

#first split into two
x_train1,x_train2,y_train1,y_train2=train_test_split(X_tr,Y_tr,test_size=0.5,random_state=5)

#second split into four
x_train01,x_train02,y_train01,y_train02=train_test_split(x_train1,y_train1,test_size=0.5,random_state=5)
x_train03,x_train04,y_train03,y_train04=train_test_split(x_train2,y_train2,test_size=0.5,random_state=5)
# 01 has 1941 rows
# 02,03,04 has 1942 rows

"""Printing the data in graphical format using pca. All four parts one after another"""

#01
pca = decomposition.PCA()
pca.n_components = 2
pca_data = pca.fit_transform(x_train01)
principalDf01 = pd.DataFrame(data = pca_data , columns = ['principal component 1', 'principal component 2'])
df= pd.DataFrame(data=y_train01,columns = ['target'])
finalDf01 = pd.concat([principalDf01, df[['target']]], axis = 1)
finalDf01

#01 
fig = plt.figure(figsize = (8,8))
ax = fig.add_subplot(1,1,1) 
ax.set_xlabel('Principal Component 1', fontsize = 15)
ax.set_ylabel('Principal Component 2', fontsize = 15)
ax.set_title('2 component PCA', fontsize = 20)
targets = [1,2,3,4,5,6,7,8,9,10,11,12]#['1', '2', '3','4','5','6','7','8','9','10','11','12']
colors = ['red', 'green', 'blue', 'pink', 'brown','yellow','cyan','grey','black','purple','olive','orange']
for target, color in zip(targets,colors):
    indicesToKeep = finalDf01['target'] == target
    ax.scatter(finalDf01.loc[indicesToKeep, 'principal component 1']
               , finalDf01.loc[indicesToKeep, 'principal component 2']
               , c = color
               , s = 50)
ax.legend(targets)
ax.grid()

#02
pca = decomposition.PCA()
pca.n_components = 2
pca_data = pca.fit_transform(x_train02)
principalDf02 = pd.DataFrame(data = pca_data , columns = ['principal component 1', 'principal component 2'])
df= pd.DataFrame(data=y_train02,columns = ['target'])
finalDf02 = pd.concat([principalDf02, df[['target']]], axis = 1)
finalDf02

#02
fig = plt.figure(figsize = (8,8))
ax = fig.add_subplot(1,1,1) 
ax.set_xlabel('Principal Component 1', fontsize = 15)
ax.set_ylabel('Principal Component 2', fontsize = 15)
ax.set_title('2 component PCA', fontsize = 20)
targets = [1,2,3,4,5,6,7,8,9,10,11,12]#['1', '2', '3','4','5','6','7','8','9','10','11','12']
colors = ['red', 'green', 'blue', 'pink', 'brown','yellow','cyan','grey','black','purple','olive','orange']
for target, color in zip(targets,colors):
    indicesToKeep = finalDf02['target'] == target
    ax.scatter(finalDf02.loc[indicesToKeep, 'principal component 1']
               , finalDf02.loc[indicesToKeep, 'principal component 2']
               , c = color
               , s = 50)
ax.legend(targets)
ax.grid()

#03
  pca = decomposition.PCA()
  pca.n_components = 2
  pca_data = pca.fit_transform(x_train03)
  principalDf03 = pd.DataFrame(data = pca_data , columns = ['principal component 1', 'principal component 2'])
  df= pd.DataFrame(data=y_train03,columns = ['target'])
  finalDf03 = pd.concat([principalDf03, df[['target']]], axis = 1)
  finalDf03

#03
fig = plt.figure(figsize = (8,8))
ax = fig.add_subplot(1,1,1) 
ax.set_xlabel('Principal Component 1', fontsize = 15)
ax.set_ylabel('Principal Component 2', fontsize = 15)
ax.set_title('2 component PCA', fontsize = 20)
targets = [1,2,3,4,5,6,7,8,9,10,11,12]#['1', '2', '3','4','5','6','7','8','9','10','11','12']
colors = ['red', 'green', 'blue', 'pink', 'brown','yellow','cyan','grey','black','purple','olive','orange']
for target, color in zip(targets,colors):
    indicesToKeep = finalDf03['target'] == target
    ax.scatter(finalDf03.loc[indicesToKeep, 'principal component 1']
               , finalDf03.loc[indicesToKeep, 'principal component 2']
               , c = color
               , s = 50)
ax.legend(targets)
ax.grid()

#04
pca = decomposition.PCA()
pca.n_components = 2
pca_data = pca.fit_transform(x_train04)
principalDf04 = pd.DataFrame(data = pca_data , columns = ['principal component 1', 'principal component 2'])
df= pd.DataFrame(data=y_train04,columns = ['target'])
finalDf04 = pd.concat([principalDf04, df[['target']]], axis = 1)
finalDf04

#04
fig = plt.figure(figsize = (8,8))
ax = fig.add_subplot(1,1,1) 
ax.set_xlabel('Principal Component 1', fontsize = 15)
ax.set_ylabel('Principal Component 2', fontsize = 15)
ax.set_title('2 component PCA', fontsize = 20)
targets = [1,2,3,4,5,6,7,8,9,10,11,12]#['1', '2', '3','4','5','6','7','8','9','10','11','12']
colors = ['red', 'green', 'blue', 'pink', 'brown','yellow','cyan','grey','black','purple','olive','orange']
for target, color in zip(targets,colors):
    indicesToKeep = finalDf04['target'] == target
    ax.scatter(finalDf04.loc[indicesToKeep, 'principal component 1']
               , finalDf04.loc[indicesToKeep, 'principal component 2']
               , c = color
               , s = 50)
ax.legend(targets)
ax.grid()

"""Implementing SVM on 01,02,03 and finding optimum value of C for each. """

#01
train_size = int(x_train01.shape[0]*0.8)
X_train = x_train01[0:train_size]
Y_train = y_train01[0:train_size]
X_val = x_train01[train_size:] #validation
Y_val = y_train01[train_size:] #validation
indx=0
accuracy = np.zeros(11)
for i in range(-5,5):
        print ('Training linear svm... for C:{}'.format(2**i))
        lsvm_clf = svm.SVC(C=2**i, kernel='linear')
        lsvm_clf.fit(X_train,Y_train)
        print ('Done!')

        print ('Calculating accuracy...')
        pred = lsvm_clf.predict(X_train)
        acc = np.sum(pred==Y_train)/float(X_train.shape[0])
        print ('Linear SVM Train Accuracy: %.4f' % acc)

        pred = lsvm_clf.predict(X_val)
        accuracy[indx] = np.sum(pred==Y_val)/float(X_val.shape[0])
        print ('Linear SVM Validation Accuracy for C=%f: %.4f' % (2**i,accuracy[indx]))
        indx += 1
plt.figure()
plt.plot(accuracy)
plt.tick_params(labelright = True)
plt.title('Validation accuracy vs C for linear SVM')

"""Optimum C = 0.25, 
Train accuracy = 0.9897, 
Validation accuracy = 0.9769
"""

#02
train_size = int(x_train02.shape[0]*0.8)
X_train = x_train02[0:train_size]
Y_train = y_train02[0:train_size]
X_val = x_train02[train_size:] #validation
Y_val = y_train02[train_size:] #validation
indx=0
accuracy = np.zeros(11)
for i in range(-5,5):
        print ('Training linear svm... for C:{}'.format(2**i))
        lsvm_clf = svm.SVC(C=2**i, kernel='linear')
        lsvm_clf.fit(X_train,Y_train)
        print ('Done!')

        print ('Calculating accuracy...')
        pred = lsvm_clf.predict(X_train)
        acc = np.sum(pred==Y_train)/float(X_train.shape[0])
        print ('Linear SVM Train Accuracy: %.4f' % acc)

        pred = lsvm_clf.predict(X_val)
        accuracy[indx] = np.sum(pred==Y_val)/float(X_val.shape[0])
        print ('Linear SVM Validation Accuracy for C=%f: %.4f' % (2**i,accuracy[indx]))
        indx += 1
plt.figure()
plt.plot(accuracy)
plt.tick_params(labelright = True)
plt.title('Validation accuracy vs C for linear SVM')

"""Optimum C = 0.125, 
Train accuracy = 0.9891, 
Validation accuracy = 0.9537
"""

#03
train_size = int(x_train03.shape[0]*0.8)
X_train = x_train03[0:train_size]
Y_train = y_train03[0:train_size]
X_val = x_train03[train_size:] #validation
Y_val = y_train03[train_size:] #validation
indx=0
accuracy = np.zeros(11)
for i in range(-5,5):
        print ('Training linear svm... for C:{}'.format(2**i))
        lsvm_clf = svm.SVC(C=2**i, kernel='linear')
        lsvm_clf.fit(X_train,Y_train)
        print ('Done!')

        print ('Calculating accuracy...')
        pred = lsvm_clf.predict(X_train)
        acc = np.sum(pred==Y_train)/float(X_train.shape[0])
        print ('Linear SVM Train Accuracy: %.4f' % acc)

        pred = lsvm_clf.predict(X_val)
        accuracy[indx] = np.sum(pred==Y_val)/float(X_val.shape[0])
        print ('Linear SVM Validation Accuracy for C=%f: %.4f' % (2**i,accuracy[indx]))
        indx += 1
plt.figure()
plt.plot(accuracy)
plt.tick_params(labelright = True)
plt.title('Validation accuracy vs C for linear SVM')

"""Optimum C = 0.25, 
Train accuracy = 0.9897, 
Validation accuracy = 0.9614

Precise estimation of best C for all 3 cases:
"""

#01
train_size = int(x_train01.shape[0]*0.8)
X_train = x_train01[0:train_size]
Y_train = y_train01[0:train_size]
X_val = x_train01[train_size:] #validation
Y_val = y_train01[train_size:] #validation
indx = 0.200
i = 0
accuracy = np.zeros(18)
while indx < 0.400 :
        print ('Training linear svm... for C:{}'.format(indx))
        lsvm_clf = svm.SVC(C=indx, kernel='linear')
        lsvm_clf.fit(X_train,Y_train)
        print ('Done!')

        print ('Calculating accuracy...')
        pred = lsvm_clf.predict(X_train)
        acc = np.sum(pred==Y_train)/float(X_train.shape[0])
        print ('Linear SVM Train Accuracy: %.4f' % acc)

        pred = lsvm_clf.predict(X_val)
        accuracy[i] = np.sum(pred==Y_val)/float(X_val.shape[0])
        print ('Linear SVM Validation Accuracy for C=%f: %.4f' % (indx,accuracy[i]))
        indx += 0.025
        i+=1
plt.figure()
plt.plot(accuracy)
plt.tick_params(labelright = True)
plt.title('Validation accuracy vs C for linear SVM')

"""Best C = 0.275"""

#02
train_size = int(x_train02.shape[0]*0.8)
X_train = x_train02[0:train_size]
Y_train = y_train02[0:train_size]
X_val = x_train02[train_size:] #validation
Y_val = y_train02[train_size:] #validation
indx = 0.075
i = 0
accuracy = np.zeros(18)
while indx < 0.250 :
        print ('Training linear svm... for C:{}'.format(indx))
        lsvm_clf = svm.SVC(C=indx, kernel='linear')
        lsvm_clf.fit(X_train,Y_train)
        print ('Done!')

        print ('Calculating accuracy...')
        pred = lsvm_clf.predict(X_train)
        acc = np.sum(pred==Y_train)/float(X_train.shape[0])
        print ('Linear SVM Train Accuracy: %.4f' % acc)

        pred = lsvm_clf.predict(X_val)
        accuracy[i] = np.sum(pred==Y_val)/float(X_val.shape[0])
        print ('Linear SVM Validation Accuracy for C=%f: %.4f' % (indx,accuracy[i]))
        indx += 0.025
        i+=1
plt.figure()
plt.plot(accuracy)
plt.tick_params(labelright = True)
plt.title('Validation accuracy vs C for linear SVM')

"""Best C = 0.125"""

#03
train_size = int(x_train03.shape[0]*0.8)
X_train = x_train03[0:train_size]
Y_train = y_train03[0:train_size]
X_val = x_train03[train_size:] #validation
Y_val = y_train03[train_size:] #validation
indx = 0.125
i = 0
accuracy = np.zeros(18)
while indx < 0.400 :
        print ('Training linear svm... for C:{}'.format(indx))
        lsvm_clf = svm.SVC(C=indx, kernel='linear')
        lsvm_clf.fit(X_train,Y_train)
        print ('Done!')

        print ('Calculating accuracy...')
        pred = lsvm_clf.predict(X_train)
        acc = np.sum(pred==Y_train)/float(X_train.shape[0])
        print ('Linear SVM Train Accuracy: %.4f' % acc)

        pred = lsvm_clf.predict(X_val)
        accuracy[i] = np.sum(pred==Y_val)/float(X_val.shape[0])
        print ('Linear SVM Validation Accuracy for C=%f: %.4f' % (indx,accuracy[i]))
        indx += 0.025
        i+=1
plt.figure()
plt.plot(accuracy)
plt.tick_params(labelright = True)
plt.title('Validation accuracy vs C for linear SVM')

"""Best C = (0.175 + 0.200)/2 = 0.1875"""

# not required as per discussion till now
#04
train_size = int(x_train04.shape[0]*0.8)
X_train = x_train04[0:train_size]
Y_train = y_train04[0:train_size]
X_val = x_train04[train_size:] #validation
Y_val = y_train04[train_size:] #validation
indx=0
accuracy = np.zeros(11)
for i in range(-5,5):
        print ('Training linear svm... for C:{}'.format(2**i))
        lsvm_clf = svm.SVC(C=2**i, kernel='linear')
        lsvm_clf.fit(X_train,Y_train)
        print ('Done!')

        print ('Calculating accuracy...')
        pred = lsvm_clf.predict(X_train)
        acc = np.sum(pred==Y_train)/float(X_train.shape[0])
        print ('Linear SVM Train Accuracy: %.4f' % acc)

        pred = lsvm_clf.predict(X_val)
        accuracy[indx] = np.sum(pred==Y_val)/float(X_val.shape[0])
        print ('Linear SVM Validation Accuracy for C=%f: %.4f' % (2**i,accuracy[indx]))
        indx += 1
plt.figure()
plt.plot(accuracy)
plt.tick_params(labelright = True)
plt.title('Validation accuracy vs C for linear SVM')

#04
train_size = int(x_train04.shape[0]*0.8)
X_train = x_train04[0:train_size]
Y_train = y_train04[0:train_size]
X_val = x_train04[train_size:] #validation
Y_val = y_train04[train_size:] #validation
# indx=0
C_optimum = ( 0.275 + 0.125 + 0.1875 )/3.0  #( 0.25 + 0.125 + 0.25)/3.0
accuracy = np.zeros(11)
# for i in range(-5,5):
print ('Training linear svm... for C:{}'.format(C_optimum))
lsvm_clf = svm.SVC(C_optimum, kernel='linear')
lsvm_clf.fit(X_train,Y_train)
print ('Done!')

print ('Calculating accuracy...')
pred = lsvm_clf.predict(X_train)
acc = np.sum(pred==Y_train)/float(X_train.shape[0])
print ('Linear SVM Train Accuracy: %.4f' % acc)

pred = lsvm_clf.predict(X_val)
accuracy = np.sum(pred==Y_val)/float(X_val.shape[0])
print ('Linear SVM Validation Accuracy for C=%f: %.4f' % (C_optimum,accuracy))
        # indx += 1
# plt.figure()
# plt.plot(accuracy)
# plt.tick_params(labelright = True)
# plt.title('Validation accuracy vs C for linear SVM')

x_test = np.loadtxt('/content/gdrive/MyDrive/HAPT Data Set.zip (Unzipped Files)/Test/X_test.txt', delimiter=' ')
y_test = np.loadtxt('/content/gdrive/MyDrive/HAPT Data Set.zip (Unzipped Files)/Test/y_test.txt')

#testing accuracy
pred = lsvm_clf.predict(x_test)
accuracy = np.sum(pred==y_test)/float(x_test.shape[0])
print ('Linear SVM Validation Accuracy for C=%f: %.4f' % (C_optimum,accuracy))

